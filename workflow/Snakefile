#### Made by IITM Team
#Ayam Gupta
#Venkatesh K

SAMPLES, = glob_wildcards("samples/{sample}.fastq.gz")  #Defining global Wild cards

# a pseudo-rule that collects the target files so the code executes in one go taking all the samples inside the data/samples/ directory
rule all:
    input:  expand("QC/multiqc"),
            expand("snps_filtered/all.snps_filtered.vcf", sample=SAMPLES),
            expand("indels_filtered/all.indels_filtered.vcf", sample=SAMPLES),

#FASTQC analysis for raw reads
rule FastQC:
    input: "samples/{sample}.fastq.gz"
    output:
        "QC/fastqc/{sample}_fastqc.html",   #output is stored in a directory QC/fastqc
        "QC/fastqc/{sample}_fastqc.zip"
    priority: 600                           #highest priority so the rule executes before any other
    threads: 2
    benchmark:
        "benchmarks/{sample}.FastQC.benchmark.txt"
    log: 
	    "logs/{sample}.FastQC.log"
    shell:
        "echo $(date '+%d/%m/%y    %H:%M:%S'): 'FastQC starts' >> {log} && echo '-' >> {log} &&"                 # Add start time to log file
        "fastqc -o QC/fastqc {input} "
        "2>> {log}"                                                                                                  # write CLI log to log file
        " && echo '-' >> {log} && echo $(date '+%d/%m/%y    %H:%M:%S'):  'FastQC {input} COMPLETE' >> {log} "
        " && echo '-' >> {log}"                                                                                      # Add end time to log file

rule MultiQC:                               #multiqc takes the output of fastqc and compiles them into one html file|| This is preferable if multiple samples are to be processed
    input: expand("QC/fastqc/{sample}_fastqc.html", sample = SAMPLES)
    output: directory("QC/multiqc")         #output in seperate directory QC/multiqc
    priority: 500
    threads: 10
    benchmark:
        "benchmarks/MultiQC.benchmark.txt"
    log: 
	    "logs/Multiqc.log"    
    shell:  
        "echo $(date '+%d/%m/%y    %H:%M:%S'): 'MultiQC starts' >> {log} && echo '-' >> {log} &&"
        "multiqc -o QC/multiqc QC/fastqc "
        "2>> {log}"                                                                                                  # write CLI log to log file
        " && echo '-' >> {log} && echo $(date '+%d/%m/%y    %H:%M:%S'):  'Multiqc COMPLETE' >> {log} "
        " && echo '-' >> {log}"                                                                                      # Add end time to log file


            

'''
rule CutAdapt:                               #adapter trimming for interleaved fastq files
    input:
        "samples/{sample}.fastq"
    output:
        "adapter_trimmed/{sample}.fastq"
    benchmark: 
        "benchmarks/CutAdapt.txt"
    log:
        "logs/CutAdapt.txt"
    params:
        forward= "ACGT",
	rev= "TCGA",
	Seq= "AACCGGTT"                     

    shell:  
        "echo $(date '+%d/%m/%y    %H:%M:%S'): 'CutAdapt starts' >> {log} && echo '-' >> {log} &&"
#        "cutadapt -a {params.Seq} -o {output} {input}"   #using the command to avoid error for test runs"
#        "cutadapt --interleaved -q 20 -a {params.forward} -A {params.rev} -o {output} {input}"
        "2>> {log}"
        " && echo '-' >> {log} && echo $(date '+%d/%m/%y    %H:%M:%S'):  'CutAdapt COMPLETE' >> {log} "
        " && echo '-' >> {log}"     
'''


rule bwa_map:                               #BWA maps the raw reads to the reference genome
    input:
        "data/Homo_sapiens_assembly38.fasta",
        "samples/{sample}.fastq.gz"               #Path to cutadapt file should be given 
    output:
        "mapped_reads/{sample}.bam"
    priority: 400                          #priority lower than fastqc so it executes after QC step when executed in one go.
    threads: 15
    log: 
	    "logs/{sample}.bwa_map.log"
    benchmark:
        "benchmarks/{sample}.bwa_map.benchmark.txt"
    shell:
        "echo $(date '+%d/%m/%y    %H:%M:%S'): 'bwa_map starts' >> {log} && echo '-' >> {log} &&"                    # Add start time to log file
        "bwa mem -M -p -t {threads} {input} | samtools view -b -h -@ {threads}  > {output} "
        "2>> {log}"                                                                                                  # write CLI log to log file
        " && echo '-' >> {log} && echo $(date '+%d/%m/%y    %H:%M:%S'):  'bwa_map {input} COMPLETE' >> {log} "
        " && echo '-' >> {log}"                                                                                      # Add end time to log file        


rule AddOrReplaceReadGroups:                            #picard suggested by GATK to avoid error down the line for picard MarkDuplicates
     input:
         "mapped_reads/{sample}.bam"
     output:
          "picard_rg/{sample}.bam"
     threads: 5
     benchmark:
         "benchmarks/{sample}.AddOrReplaceReadGroups.benchmark.txt"
     log: 
         "logs/{sample}.AddOrReplaceReadGroups.log"
     shell:
          "echo $(date '+%d/%m/%y    %H:%M:%S'): 'AddOrReplaceReadGroups starts' >> {log} && echo '-' >> {log} &&"                    # Add start time to log file
          "picard AddOrReplaceReadGroups I={input} O={output} RGID=1 RGLB=lib2 RGPL=ILLUMINA RGPU=unit1 RGSM={wildcards.sample} "
          "2>> {log}"                                                                                                  # write CLI log to log file
          " && echo '-' >> {log} && echo $(date '+%d/%m/%y    %H:%M:%S'):  'AddOrReplaceReadGroups {input} COMPLETE' >> {log} "
          " && echo '-' >> {log}"                                                                                      # Add end time to log file        



rule SortSam:                          #picard_sort will do the sorting of each sample || Parameters as suggested by GATK >> VALIDATION_STRINGENCY=LENIENT SORT_ORDER=coordinate MAX_RECORDS_IN_RAM=3000000 CREATE_INDEX=True.
    input:
        "picard_rg/{sample}.bam"
    output:
        "picard_sort/{sample}.sort.bam"
    threads: 5
    benchmark:
        "benchmarks/{sample}.SortSam.benchmark.txt"    
    log: 
        "logs/{sample}.SortSam.log"
    shell:
        "echo $(date '+%d/%m/%y    %H:%M:%S'): 'SortSam starts' >> {log} && echo '-' >> {log} &&"                    # Add start time to log file
        "picard -Xmx13g SortSam I={input} O={output} VALIDATION_STRINGENCY=LENIENT SORT_ORDER=coordinate MAX_RECORDS_IN_RAM=3000000 CREATE_INDEX=True "
        "2>> {log}"                                                                                                  # write CLI log to log file
        " && echo '-' >> {log} && echo $(date '+%d/%m/%y    %H:%M:%S'):  'SortSam {input} COMPLETE' >> {log} "
        " && echo '-' >> {log}"                                                                                      # Add end time to log file        



rule MarkDuplicates:                       #Picard MarkDuplicates to remove duplicate reads
    input:
        "picard_sort/{sample}.sort.bam"
    output:
        bam= "picard_markdups/{sample}.sort.dup.bam",
        met= "metrics/{sample}_marked_dup_metrics.txt"
    threads: 5
    benchmark:
        "benchmarks/{sample}.MarkDuplicates.benchmark.txt"
    log: 
    	"logs/{sample}.MarkDuplicates.log"
    shell:
        "echo $(date '+%d/%m/%y    %H:%M:%S'): 'MarkDuplicates starts' >> {log} && echo '-' >> {log} &&"                    # Add start time to log file
        "picard -Xmx13g MarkDuplicates I={input} O={output.bam} METRICS_FILE={output.met} "
        "2>> {log}"                                                                                                  # write CLI log to log file
        " && echo '-' >> {log} && echo $(date '+%d/%m/%y    %H:%M:%S'):  'MarkDuplicates {input} COMPLETE' >> {log} "
        " && echo '-' >> {log}"                                                                                      # Add end time to log file        


rule BaseRecalibrator:                     #BaseRecalibrator step musy include a --known sites parameter taking the dbsnp input
     input:
         bam= "picard_markdups/{sample}.sort.dup.bam",
         fa= "data/Homo_sapiens_assembly38.fasta",
         dbsnp= "data/00-All.vcf.gz"
     output:
         "base_reclabritor/{sample}_recal_data.table"
     threads: 5
     log: "logs/{sample}.BaseRecalibrator.log"
     benchmark:
          "benchmarks/{sample}.BaseRecalibrator.benchmark.txt"
     shell:
          "echo $(date '+%d/%m/%y    %H:%M:%S'): 'MarkDuplicates starts' >> {log} && echo '-' >> {log} &&"                    # Add start time to log file
          "gatk --java-options -Xmx13g BaseRecalibrator -I {input.bam} -R {input.fa} --known-sites {input.dbsnp} -O {output} "
          "2>> {log}"                                                                                                  # write CLI log to log file
          " && echo '-' >> {log} && echo $(date '+%d/%m/%y    %H:%M:%S'):  'BaseRecalibrator {input} COMPLETE' >> {log} "
          " && echo '-' >> {log}"                                                                                      # Add end time to log file        


rule ApplyBQSR:                            #ApplyBQSR takes multiple inputs || genome.fa (reference genome) || bam generated from previous step|| output of BaseRecalibrator file
       input:
           bam= "picard_markdups/{sample}.sort.dup.bam",
           fa= "data/Homo_sapiens_assembly38.fasta",
           recal= "base_reclabritor/{sample}_recal_data.table"
       output:
            "bqsr/{sample}.sort.dup.bqsr.gatk.bam"
       threads: 5
       log: "logs/{sample}.ApplyBQSR.log"
       benchmark:
            "benchmarks/{sample}.ApplyBQSR.benchmark.txt"
       shell:
            "echo $(date '+%d/%m/%y    %H:%M:%S'): 'ApplyBQSR starts' >> {log} && echo '-' >> {log} &&"                    # Add start time to log file
            "gatk --java-options -Xmx13g ApplyBQSR -I {input.bam} -R {input.fa} --bqsr-recal-file {input.recal} -O {output} "
            "2>> {log}"                                                                                                  # write CLI log to log file
            " && echo '-' >> {log} && echo $(date '+%d/%m/%y    %H:%M:%S'):  'ApplyBQSR {input} COMPLETE' >> {log} "
            " && echo '-' >> {log}"                                                                                      # Add end time to log file        



rule HaplotypeCaller:                       #haplotypecaller will call for varients requires reference genome file along with output of previous step.
       input:
           gatk= "bqsr/{sample}.sort.dup.bqsr.gatk.bam",
           fa= "data/Homo_sapiens_assembly38.fasta"
       output:
            "gvcf/{sample}.g.vcf.gz"
       priority: 300
       threads: 5
       log: "logs/{sample}.HaplotypeCaller.log"
       benchmark:
            "benchmarks/{sample}.HaplotypeCaller.benchmark.txt"
       shell:
            "echo $(date '+%d/%m/%y    %H:%M:%S'): 'HaplotypeCaller starts' >> {log} && echo '-' >> {log} &&"                    # Add start time to log file
            "gatk --java-options -Xmx13g HaplotypeCaller -I {input.gatk} -R {input.fa} -ERC GVCF -O {output} "
            "2>> {log}"                                                                                                  # write CLI log to log file
            " && echo '-' >> {log} && echo $(date '+%d/%m/%y    %H:%M:%S'):  'HaplotypeCaller {input} COMPLETE' >> {log} "
            " && echo '-' >> {log}"                                                                                      # Add end time to log file        

rule gatk_CombineGVCFs:                                                 #Combining the vcfs generetaed seperatly for each sample into one
    input:
        vcf_dummy = expand("gvcf/{sample}.g.vcf.gz", sample = SAMPLES), # a dummy vcf to connect this rule to gatk_HaplotypeCaller
        fa = "data/Homo_sapiens_assembly38.fasta",

    output:
        gvcf = "gvcf_combined/all.g.vcf.gz",
    params:
        list = "gvcfs.list"
    priority: 200
    benchmark:
         "benchmarks/CombineGVCFs.benchmark.txt"
    threads:15
    log: "logs/CombineGVCFs.log"
    shell:
         "echo $(date '+%d/%m/%y    %H:%M:%S'): 'CombineGVCFs starts' >> {log} && echo '-' >> {log} &&"                    # Add start time to log file
         "ls gvcf/*.gz >gvcfs.list && gatk --java-options -Xmx13g CombineGVCFs -R {input.fa} --variant {params.list} -O {output.gvcf} "   #Two bash comands running sequentially to avoid empty gvcf.list
         "2>> {log}"                                                                                                  # write CLI log to log file
         " && echo '-' >> {log} && echo $(date '+%d/%m/%y    %H:%M:%S'):  'CombineGVCFs {input} COMPLETE' >> {log} "
         " && echo '-' >> {log}"                                                                                      # Add end time to log file        



rule GenotypeGVCFs:                         #GenotypeGVCFs convert the gVCF to VCF.
       input:
            fa = "data/Homo_sapiens_assembly38.fasta",
            gvcf= "gvcf_combined/all.g.vcf.gz"
       output:
            "vcf/all.vcf.gz"
       threads: 15
       priority: 100
       log: "logs/GenotypeGVCFs.log"
       benchmark:
            "benchmarks/GenotypeGVCF.benchmark.txt"
       shell:
            "echo $(date '+%d/%m/%y    %H:%M:%S'): 'GenotypeGVCFs starts' >> {log} && echo '-' >> {log} &&"                    # Add start time to log file
            "gatk --java-options -Xmx13g GenotypeGVCFs -R {input.fa} -V {input.gvcf} -O {output} "
            "2>> {log}"                                                                                                  # write CLI log to log file
            " && echo '-' >> {log} && echo $(date '+%d/%m/%y    %H:%M:%S'):  'GenotypeGVCFs COMPLETE' >> {log} "
            " && echo '-' >> {log}"                                                                                      # Add end time to log file        



rule LeftAlignAndTrimVariants:              #LeftAlignAndTrimVariants
        input:
            fa= "data/Homo_sapiens_assembly38.fasta",
            vcf= "vcf/all.vcf.gz"
        output:
            "trim_vcf/all.trim.vcf"
        threads: 15
        log: "logs/LeftAlignAndTrimVariants.log"
        benchmark:
             "benchmarks/LeftAlignAndTrimVariants.benchmark.txt"
        shell:
            "echo $(date '+%d/%m/%y    %H:%M:%S'): 'LeftAlignAndTrimVariants starts' >> {log} && echo '-' >> {log} &&"                    # Add start time to log file
            "gatk --java-options -Xmx13g LeftAlignAndTrimVariants -R {input.fa} -V {input.vcf} -O {output} --split-multi-allelics "
            "2>> {log}"                                                                                                  # write CLI log to log file
            " && echo '-' >> {log} && echo $(date '+%d/%m/%y    %H:%M:%S'):  'LeftAlignAndTrimVariants COMPLETE' >> {log} "
            " && echo '-' >> {log}"                                                                                      # Add end time to log file        


rule SelectVariants_SNPS:                   #Selects SNPS only
        input:
            "trim_vcf/all.trim.vcf"
        output:
            "snps/all.vcf"
        threads: 15
        log: "logs/SelectVariants_SNPS.log"
        benchmark:
            "benchmarks/SelectVariants_SNPS.benchmark.txt"
        shell:
            "echo $(date '+%d/%m/%y    %H:%M:%S'): 'SelectVariants_SNPS starts' >> {log} && echo '-' >> {log} &&"                    # Add start time to log file
            "gatk --java-options -Xmx13g SelectVariants -V {input} -select-type SNP -O {output} "
            "2>> {log}"                                                                                                  # write CLI log to log file
            " && echo '-' >> {log} && echo $(date '+%d/%m/%y    %H:%M:%S'):  'SelectVariants_SNPS COMPLETE' >> {log} "
            " && echo '-' >> {log}"                                                                                      # Add end time to log file        


rule SelectVariants_INDELS:                  #Selects indels only
        input:
            "trim_vcf/all.trim.vcf"
        output:
            "indels/all.vcf"
        threads: 15
        log: "logs/SelectVariants_INDELS.log"
        benchmark:
            "benchmarks/SelectVariants_INDELS.benchmark.txt"
        shell:
            "echo $(date '+%d/%m/%y    %H:%M:%S'): 'SelectVariants_INDELS starts' >> {log} && echo '-' >> {log} &&"                    # Add start time to log file
            "gatk --java-options -Xmx13g SelectVariants -V {input} -select-type INDEL -O {output} "
            "2>> {log}"                                                                                                  # write CLI log to log file
            " && echo '-' >> {log} && echo $(date '+%d/%m/%y    %H:%M:%S'):  'SelectVariants_INDELS COMPLETE' >> {log} "
            " && echo '-' >> {log}"                                                                                      # Add end time to log file        


rule VariantFiltration_SNP:                            #Hard filtering snps as per the GATK pipeline with their suggested parameters
        input:
            "snps/all.vcf"
        output:
            "snps_filtered/all.snps_filtered.vcf"
        params:
            flt= """-filter "QD < 2.0" --filter-name "QD2" \
                    -filter "QUAL < 30.0" --filter-name "QUAL30" \
                    -filter "SOR > 3.0" --filter-name "SOR3" \
                    -filter "FS > 60.0" --filter-name "FS60" \
                    -filter "MQ < 40.0" --filter-name "MQ40" \
                    -filter "MQRankSum < -12.5" --filter-name "MQRankSum-12.5" \
                    -filter "ReadPosRankSum < -8.0" --filter-name "ReadPosRankSum-8" """,
        threads: 20
        log: "logs/VariantFiltration_SNP.log"
        benchmark:
            "benchmarks/VariantFiltration_SNP.benchmark.txt"
        shell:
            "echo $(date '+%d/%m/%y    %H:%M:%S'): 'VariantFiltration_SNP starts' >> {log} && echo '-' >> {log} &&"                    # Add start time to log file
            "gatk --java-options -Xmx13g VariantFiltration -V {input} {params.flt} -O {output} "
            "2>> {log}"                                                                                                  # write CLI log to log file
            " && echo '-' >> {log} && echo $(date '+%d/%m/%y    %H:%M:%S'):  'VariantFiltration_SNP COMPLETE' >> {log} "
            " && echo '-' >> {log}"                                                                                      # Add end time to log file        



rule VariantFiltration_INDELS:                                   #Hard filtering indels as per the GATK pipeline with their suggested parameters
        input:
            "indels/all.vcf"
        output:
            "indels_filtered/all.indels_filtered.vcf"
        params:
            flt= """-filter "QD < 2.0" --filter-name "QD2" \
                    -filter "QUAL < 30.0" --filter-name "QUAL30" \
                    -filter "FS > 200.0" --filter-name "FS200" \
                    -filter "ReadPosRankSum < -20.0" --filter-name "ReadPosRankSum-20" """,
        threads: 20
        log: "logs/VariantFiltration_indels.log"
        benchmark:
            "benchmarks/VariantFiltration_INDELS.benchmark.txt"
        shell:
            "echo $(date '+%d/%m/%y    %H:%M:%S'): 'VariantFiltration_INDELS starts' >> {log} && echo '-' >> {log} &&"                    # Add start time to log file
            "gatk --java-options -Xmx13g VariantFiltration -V {input} {params.flt} -O {output} "
            "2>> {log}"                                                                                                  # write CLI log to log file
            " && echo '-' >> {log} && echo $(date '+%d/%m/%y    %H:%M:%S'):  'VariantFiltration_INDELS COMPLETE' >> {log} "
            " && echo '-' >> {log}"                                                                                      # Add end time to log file        



